"""
Quick test script to verify Ollama and phi3:mini are working
"""

import requests
import time

def test_ollama():
    """Test if Ollama is running and phi3:mini is available"""
    
    print("=" * 60)
    print("ğŸ” Testing Ollama Setup")
    print("=" * 60)
    print()
    
    # Test 1: Check if Ollama is running
    print("Test 1: Checking if Ollama is running...")
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollama is running")
            
            # List available models
            data = response.json()
            models = [m.get('name', '') for m in data.get('models', [])]
            print(f"ğŸ“¦ Available models: {', '.join(models)}")
            
            if 'phi3:mini' in models:
                print("âœ… phi3:mini is installed")
            else:
                print("âŒ phi3:mini NOT found. Run: ollama pull phi3:mini")
                return False
        else:
            print(f"âŒ Ollama returned status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Cannot connect to Ollama: {e}")
        print("ğŸ’¡ Make sure Ollama is running: ollama serve")
        return False
    
    print()
    
    # Test 2: Test phi3:mini response speed
    print("Test 2: Testing phi3:mini response speed...")
    print("Sending test prompt...")
    
    start = time.time()
    
    try:
        payload = {
            "model": "phi3:mini",
            "prompt": "What are prenatal vitamins?",
            "stream": False,
            "options": {
                "num_predict": 150,
                "temperature": 0.5,
                "top_k": 20,
                "top_p": 0.8,
                "num_ctx": 1024,
                "num_thread": 8
            }
        }
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json=payload,
            timeout=60
        )
        
        elapsed = time.time() - start
        
        if response.status_code == 200:
            data = response.json()
            answer = data.get('response', '').strip()
            
            print(f"âœ… Response received in {elapsed:.1f} seconds")
            print()
            print("ğŸ“ Sample response:")
            print("-" * 60)
            print(answer[:200] + "..." if len(answer) > 200 else answer)
            print("-" * 60)
            print()
            
            # Evaluate speed
            if elapsed < 20:
                print("ğŸš€ EXCELLENT: Response time < 20s")
            elif elapsed < 30:
                print("âœ… GOOD: Response time < 30s")
            elif elapsed < 45:
                print("âš ï¸ ACCEPTABLE: Response time < 45s")
            else:
                print("âŒ TOO SLOW: Response time > 45s")
                print("ğŸ’¡ Try restarting Ollama or closing other apps")
            
            return True
        else:
            print(f"âŒ Request failed with status {response.status_code}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ Request timed out (> 60s)")
        print("ğŸ’¡ Model might be too slow. Try restarting Ollama.")
        return False
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False
    
    print()

if __name__ == "__main__":
    success = test_ollama()
    
    print()
    print("=" * 60)
    if success:
        print("âœ… ALL TESTS PASSED")
        print("=" * 60)
        print()
        print("ğŸ‰ Your setup is ready!")
        print()
        print("Next steps:")
        print("1. Start backend: cd backend && python run_backend.py")
        print("2. Start frontend: cd frontend-react && npm run dev")
        print("3. Open: http://localhost:3000")
    else:
        print("âŒ TESTS FAILED")
        print("=" * 60)
        print()
        print("Please fix the issues above before starting the app.")
    print()
